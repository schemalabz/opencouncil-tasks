# OpenCouncil Tasks

Backend task processing service for the [OpenCouncil](https://github.com/schemalabz/opencouncil) platform. This service handles various audio, video, and content processing tasks through both a REST API and CLI interface.

## üéØ Supported Tasks

The server supports the following processing tasks:

### Content Processing
- [`processAgenda`](src/tasks/processAgenda.ts) - Extracts and structures agenda information from documents
- [`fixTranscript`](src/tasks/fixTranscript.ts) - Cleans and corrects transcription output for improved accuracy
- [`summarize`](src/tasks/summarize.ts) - Generates comprehensive content summaries with subject extraction
- [`generatePodcastSpec`](src/tasks/generatePodcastSpec.ts) - Generates podcast specifications for content distribution

### Media Processing
- [`downloadYTV`](src/tasks/downloadYTV.ts) - Downloads YouTube videos and extracts audio with optimized quality settings
- [`splitMediaFile`](src/tasks/splitMediaFile.ts) - Splits media files into smaller segments with precise timestamp control
- [`uploadToSpaces`](src/tasks/uploadToSpaces.ts) - Handles secure file uploads to cloud storage with public access URLs

### Transcription & Diarization
- [`diarize`](src/tasks/diarize.ts) - Identifies and separates different speakers in audio recordings
- [`splitAudioDiarization`](src/tasks/splitAudioDiarization.ts) - Splits audio files based on speaker segments with configurable duration limits
- [`transcribe`](src/tasks/transcribe.ts) - Converts audio to text with support for custom vocabulary and prompts
- [`applyDiarization`](src/tasks/applyDiarization.ts) - Applies speaker identification to existing transcripts
- [`generateVoiceprint`](src/tasks/generateVoiceprint.ts) - Creates unique speaker voice fingerprints for identification

### Data Synchronization
- [`syncElasticsearch`](src/tasks/syncElasticsearch.ts) - Triggers and monitors a data synchronization job between PostgreSQL and Elasticsearch.

The [`pipeline`](src/tasks/pipeline.ts) task orchestrates multiple tasks above in sequence, providing a complete end-to-end processing workflow.

## üõ†Ô∏è Development Setup

### Prerequisites

- Node.js ^20.11.1
- FFmpeg
- Required API keys (see [Configuration](#configuration) section)

Clone the repository:
```bash
git clone https://github.com/schemalabz/opencouncil-tasks.git
cd opencouncil-tasks
```

Copy the example environment file:
```bash
cp .env.example .env
```

Then edit the file to include your specific [configuration values](#configuration).


### Docker Setup (Recommended)

The Docker setup includes the main service, the Cobalt API service for YouTube video processing, and the Elastic connector for data synchronization.

#### Standalone Mode

If you are running this service by itself without needing to connect to the main OpenCouncil application, you can start it with the standard command:

```bash
# This runs the app service and its dependencies
docker compose up app
```

#### Integrated Development Mode

This mode is for when you are developing locally and need this service to communicate with the main `opencouncil` application.

**Prerequisite**

Before starting in this mode, you must first start the main `opencouncil` project using its `./run.sh` script. This step is essential because it creates the shared Docker network named `opencouncil-net` that this project will connect to.

**Command**

Once the `opencouncil` project is running, start this tasks service with the following command:

```bash
# Use this for local development alongside the main opencouncil project
docker compose -f docker-compose.yml -f docker-compose.dev.yml up app
```

**How it Works**

This command uses the `docker-compose.dev.yml` file, which tells Docker to connect this project's services to the `external` network named `opencouncil-net`.

This allows the two projects to communicate directly and efficiently within Docker.

### Manual Setup
```bash
npm install
npm run dev
```

Note: If you're not using a remote Cobalt API instance, you'll need to run the Cobalt API service separately:
```
COBALT_API_BASE_URL=http://localhost:3002 docker compose up cobalt-api
```

Then ensure your `.env` file has:
```
COBALT_API_BASE_URL=http://localhost:3002
```

## üîÑ Callback Server

The service includes a callback server that handles asynchronous task completion notifications. This is particularly important when working with external services that need to notify our server about task completion.

For local development, you'll need to expose your local server to the internet. We recommend using [ngrok](https://ngrok.com/) for this purpose:

```bash
ngrok http 3005
```

Then, update your `.env` file with the ngrok URL:
```
PUBLIC_URL=https://your-ngrok-url.ngrok.io
```

## CLI Interface

The CLI interface provides direct access to individual tasks and starts its own server instance for handling callbacks. To see all available commands and their options, run:

```bash
npm run cli -- --help
```

## Configuration

The service uses environment variables for configuration. Not all variables are required for all tasks - you only need to configure the ones relevant to the tasks you plan to use.

### Server Configuration
- `PORT` (default: 3000) - The port the server will listen on
- `DATA_DIR` (default: ./data) - Directory for storing data files
- `NO_AUTH` (default: false) - Disable API authentication for development
- `CORS_ORIGINS_ALLOWED` - Comma-separated list of allowed CORS origins
- `PUBLIC_URL` - Public URL for callback server (required for external service callbacks)
- `MAX_PARALLEL_TASKS` (default: 10) - Maximum number of concurrent tasks

### Authentication
- `API_TOKENS` - JSON array of valid API tokens for authentication
  - Can also be provided through `./secrets/apiTokens.json` file

### Storage
- `DO_SPACES_KEY` - Digital Ocean Spaces access key
- `DO_SPACES_SECRET` - Digital Ocean Spaces secret key
- `DO_SPACES_ENDPOINT` - Digital Ocean Spaces endpoint
- `DO_SPACES_BUCKET` - Digital Ocean Spaces bucket name
- `CDN_BASE_URL` - Base URL for CDN access

### External Services
- `ANTHROPIC_API_KEY` - Required for summarization and content generation
- `GLADIA_API_KEY` - Required for transcription
- `PERPLEXITY_API_KEY` - Required for agenda processing
- `MUX_TOKEN_ID` and `MUX_TOKEN_SECRET` - Required for video processing
- `GOOGLE_API_KEY` - Required for geocoding
- `ADALINE_SECRET` - Secret for Adaline service integration
- `PYANNOTE_API_TOKEN` - Required for speaker diarization
- `PYANNOTE_DIARIZE_API_URL` - Pyannote API endpoint
- `MOCK_PYANNOTE` - Enable mock mode for Pyannote (development only)
- `ELASTICSEARCH_HOST` - Elasticsearch host URL
- `ELASTICSEARCH_API_KEY` - Elasticsearch API key for the connector
- `ELASTICSEARCH_CONNECTOR_ID` - The ID of the Elasticsearch connector

### Task-Specific Configuration
- `GLADIA_MAX_CONCURRENT_TRANSCRIPTIONS` (default: 20) - Maximum concurrent transcription tasks
- `PYANNOTE_MAX_CONCURRENT_DIARIZATIONS` (default: 5) - Maximum concurrent diarization tasks
- `COBALT_API_BASE_URL` (default: http://cobalt-api:9000) - YouTube download service URL
  - For Docker setup, this points to the internal Docker network
  - For manual setup, point to your Cobalt API instance
- `LOG_DIR` - Directory for log files
